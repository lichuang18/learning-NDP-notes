Cognitive SSD: A Deep Learning Engine for In-Storage Data Retrieval

问题（动机）：
数据分析与检索是现有人工智能系统中应用最为广泛的组成部分。然而，每个请求必须经过I/O堆栈的每一层，这将在二级存储之间移动大量不相关的数据，
DRAM和片上缓存。这将导致高响应延迟和上升的能耗。
solution：Cognitive SSD   在闪存旁边放置了一个名为DLG-x的快速访问加速器，以实现近数据深度学习和图搜索。
          NVMe命令扩展，实现深度学习和图搜索等功能
          
结果：
    latency：Cognitive SSD相比CPU+SSD   69.9%降低
    全系统power consumption： CPU 34.4%降低，  GPU  63.0%降低（相当性能）
译文：

1.Introduction

          非结构化数据，特别是无标签的视频和图像等，近年来呈爆炸式增长。据悉，在商用数据中心[10]中，非结构化数据占用的存储容量高达80%。
一旦在云机器中存储和管理大量的非结构化数据，就会导致用户发出密集的检索请求，这对数据中心[19]的处理吞吐量和功耗构成了重大挑战。
因此，在云服务基础设施中支持快速和高效的数据检索对于降低数据中心的总拥有成本(TCO)至关重要。
          然而，传统的基于内容的多媒体数据检索系统在处理大规模非结构化数据时存在着准确性不高、功耗低、成本高等问题。
图1(a)简要描述了一个典型的基于内容的数据检索系统，该系统由CPU/GPU和基于计算中心架构[14]的传统存储设备组成。 
当来自互联网或中央服务器的数据检索请求到达时，CPU必须将大量潜在数据从磁盘重新加载到临时DRAM[14]中，并将查询的特性与加载的非结构化数据的特性相匹配，
以找到相关的目标。这种以计算为中心的体系结构面临着开销和效率低下的几个关键来源。(1)如图1(a)所示，当前的I/O软件堆栈在检索请求[60]时简单地从存储设备获取数据，
从而大大增加了数据检索系统的负担。据报道，随着hdd被非易失性内存所取代[41,48]性能瓶颈从硬件(75 ~ 50us[11])转移到了软件(60.8us [48])。
(2)在传统的内存层次结构中，大量的数据移动会带来能量和延迟开销。随着查询数据规模的增加，这个问题变得越来越严重，
因为底层存储的相关数据在到达CPU或gpu[24]的计算单元之前必须通过缓慢的I/O接口(例如SATA)、主内存和多级缓存，如图1(a)所示。
          为了解决这些问题，如图1(b)所示，本工作旨在在紧凑的存储设备内定制一个统一的数据存储和检索系统，消除主要的IO和数据移动瓶颈。
在该系统中，检索请求直接发送到存储设备，目标数据分析和索引完全在非结构化数据所在的地方执行。建立这样一个基于Cognitive SSD的数据检索系统,遵循着
以下设计目标:(1)提供高精度,低延迟,和能源高效的查询机制对于一个紧凑的SSD是可负担的,(2)利用flash设备的内部带宽在SSD节能深度学习的基础数据处理、
和(3)使开发人员能够针对不同的数据集定制数据检索系统。下面将详细说明这些要点。  
          首先，不要依赖于图1(a)中的通用CPU或GPU设备，考虑到SSD的形状因素和成本，我们必须有一个高度计算效率和精确的数据检索架构。
传统的数据检索框架是不准确的，或者在资源受限的SSD中实现的计算成本太高。
在这项工作中，我们首次提出了一种结合深度学习和图搜索算法(DLG)的整体数据检索机制，前者可以提取非结构化数据的语义特征，后者可以提高数据库搜索效率。
DLG解决方案实现了更高的数据检索精度，并通过深度学习模型定制实现了用户自定义的计算复杂性，使得在SSD中实现灵活高效的端到端非结构化数据检索系统成为可能。
          其次，尽管DLG是一种简单而灵活的端到端数据检索解决方案，但将其嵌入到ssd中仍然需要大量的工作。我们设计了一个特殊的硬件加速器，它同时支持深度哈希和图搜索，
dlg-x，构建目标cognitive SSD，而不使用电力不可持续的CPU或GPU解决方案。然而，SSD中有限的DRAM主要用于缓存flash管理的元数据，没有为深度学习应用程序留下可用空间。
幸运的是，我们已经证明了在典型的SSD中，内部flash接口的带宽超过了外部IO接口的带宽，通过适当的数据布局映射来匹配dlg -x的带宽需求。
DLG-x通过重建SSD中的数据路径，并刻意优化NAND闪存上深度学习模型和图形相关的数据布局，充分利用内部并行性，绕过板载DRAM直接从NAND闪存访问数据。
          最后，随着我们将深度学习技术引入SSD，我们必须公开cognitive SSD的软件抽象提供给用户和开发人员使用不同的深度学习模型处理不同的数据结构。
因此，我们利用NVMe协议[6]进行命令扩展，将底层的深度学习机制、特征分析和数据结构索引机制抽象为用户可见调用。
不仅用户的请求可以触发dlg -x加速器来搜索目标数据集中与查询相关的结构，而且系统开发人员可以根据不同的数据集和性能需求自由配置具有不同表示能力和开销的深度哈希架构。
与传统的特别解决方案相比，认知SSD允许系统开发人员通过提供的api调整检索精度和数据检索服务的实时性能。同时，认知SSD还支持特殊命令的灵活组合，以实现不同的数据检索相关任务，
如存储内数据分类和hash -only功能。综上所述，我们做出了以下新颖的贡献:
          1.我们提出了认知SSD，通过集成专门的深度学习和图搜索加速器(DLG-x)，实现SSD内深度学习和图搜索。DLGx直接从NAND闪存访问数据，不需要跨越多个内存层次结构，减少了数据移动路径和功耗。
据我们所知，这项工作是首次将深度学习和图搜索方法结合起来，在SSD中快速准确地检索数据。
          2.我们采用认知SSD构建了一个无服务器的数据检索系统，完全抛弃了传统计算中心系统的传统数据查询机制。它能独立响应数据检索请求，速度快，能耗低。
它还可以扩展到多ssd系统，并显著降低数据中心中大规模存储节点的硬件和电力开销。
          3.我们在Cosmos plus OpenSSD平台[7]上构建了认知SSD的原型，并使用它来实现一个数据检索系统。我们的评估结果证明了这一点
认知SSD比在CPU和GPU上实现的多媒体检索系统更节能，比在CPU上实现的平均延迟减少69.9%。我们还表明，当认知SSD向外扩展形成智能轻量化存储节点(包括connected)时，
它的性能优于数据中心中使用的传统计算和存储节点认知SSD数组。
