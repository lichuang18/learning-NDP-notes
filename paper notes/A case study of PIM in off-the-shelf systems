问题：memory wall
现状：设计in or near内存中执行计算的系统已经被提出了几十年,然而大多数都无法通过blueprints和模拟。
      而且当硬件实际构建并集成到一个完全功能的系统时，它必须处理在模拟中可能被忽略的显示约束。
      所以评估一个真正的硬件实现可以得到有价值的理解
工作：在5个常用的应用程序上进行实验，突出了这种架构的主要优势：计算能力、memory内部带宽的规模和memory size
结果：这一特性帮助一些应用程序克服了Von-Neumann瓶颈，但对于其他应用程序，这种架构限制了其达到高的资源利用率，paper对这些问题进行了探究，分析并给出了原因。

译文：

1.Introduction
    几十年来，内存墙一直困扰着计算机系统。也被称为冯·诺伊曼瓶颈，它发生在CPU通过一个有限的通道连接到主存储器的系统中，限制了带宽并延长了数据访问的延迟。
几十年来，计算机科学家一直在追求in or near memory计算的想法，旨在使计算更接近数据。然而，大多数提出的硬件从未通过仿真或专利原型，因此，关于这项技术的一些问题无法回答。
当我们获得了即将上市的具有通用处理能力的DRAM的早期访问权时，我们认识到一个独特的机会，可以更好地理解其集成到现有系统中的局限性。
过去提出的大多数解决方案都需要专用的硬件，这些硬件在某种程度上与当前部署的系统不兼容[2,3,9,14,16]。我们评估的硬件是专门为替代传统DRAM而设计的，这带来了许多模拟架构中不存在的一些限制。
    UPMEM的DRAM内存包括通用处理器，称为DRAM处理单元(DPU)[5]。每一个64MB的DRAM片有一个专用的DPU，因此计算资源随内存大小而变化。利用这种硬件的优势，我们移植了五个需要高内存带宽的应用程序，
它们的计算需求会随着数据的大小而增加。我们观察到，应用程序的吞吐量确实随数据大小而变化，但这种变化并不总是这种硬件所能达到的最佳效果。主要原因是，在不复制的情况下，
很难从主机CPU访问位于DRAM with DPU中的数据，dpu的处理能力有限，以及控制dpu的粒度。  
